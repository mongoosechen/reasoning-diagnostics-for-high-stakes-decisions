# Reasoning Diagnostics for High-Stakes Decisions

**A small diagnostic tool for detecting framing mistakes and layer confusion when experts reason under deep uncertainty.**

Designed for contexts such as AI governance, policy analysis, risk assessment, and cause prioritisation.

---

## The problem

In high-stakes domains, we often see:

- experts strongly disagreeing
- debates that never converge
- policies that backfire
- moral arguments that fail to resolve issues
- decisions that feel unstable even after careful analysis

These are usually explained as:
- lack of data
- value disagreement
- forecasting difficulty
- institutional complexity

But many of these failures share a deeper pattern:

> Smart people reasoning carefully inside a misframed problem.

---

## The tool

This repo introduces two simple diagnostics:

### 1. Frame Mismatch
Is this being treated as a prediction problem over time, when it is actually about structural change in a system?

### 2. Layer Confusion
Are people mixing up:
- what humans can only respond to,
- how humans arrange their responses,
- and how humans judge what happened?

These diagnostics often explain why disagreements persist and why interventions misfire.

---

## The 4 diagnostic questions

Before analysing a high-stakes issue, ask:

1. Is this framed as predicting outcomes over time, when it is actually about structural change?
2. Are participants answering different types of problems without realising it?
3. Are these discussions mixing what is non-negotiable, what is designable, and what is interpretive?
4. If everyone had the same information and reasoned carefully, would this disagreement still remain?

If yes, the issue is likely misframed.

---

## Worked example

See:  
`worked-example.md`

A demonstration of how this tool applies to a real decision guide discussing expert disagreement and uncertainty.

---

## How to use this (10 minutes)

See:  
`decision-diagnostic-cheatsheet.md`

A quick method to apply this when analysing AI risk, policy debates, or prioritisation problems.

---

## What this is not

- Not a forecasting method
- Not a moral argument
- Not a theory of AI or policy
- Not a full framework

It is a small diagnostic lens to prevent reasoning errors before analysis begins.
